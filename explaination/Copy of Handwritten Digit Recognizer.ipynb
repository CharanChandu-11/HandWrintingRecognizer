{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8860,
     "status": "ok",
     "timestamp": 1750265982946,
     "user": {
      "displayName": "Charan Gaming11",
      "userId": "16907770713425715637"
     },
     "user_tz": -330
    },
    "id": "PbH7sDDdpCne",
    "outputId": "07a9c7b7-c33b-46e2-ed55-11288e988bee"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chara\\OneDrive\\Pictures\\Documents\\MACHINE LEARNING\\HandWritingRecognizer\\mnist_env\\Lib\\site-packages\\tensorflow\\__init__.py:468\u001b[39m\n\u001b[32m    466\u001b[39m     importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33mtf_keras.src.optimizers\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    467\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m     \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkeras.src.optimizers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[32m    470\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chara\\OneDrive\\Pictures\\Documents\\MACHINE LEARNING\\HandWritingRecognizer\\mnist_env\\Lib\\site-packages\\keras\\__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _tf_keras \u001b[38;5;28;01mas\u001b[39;00m _tf_keras\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations \u001b[38;5;28;01mas\u001b[39;00m activations\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications \u001b[38;5;28;01mas\u001b[39;00m applications\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chara\\OneDrive\\Pictures\\Documents\\MACHINE LEARNING\\HandWritingRecognizer\\mnist_env\\Lib\\site-packages\\keras\\_tf_keras\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chara\\OneDrive\\Pictures\\Documents\\MACHINE LEARNING\\HandWritingRecognizer\\mnist_env\\Lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations \u001b[38;5;28;01mas\u001b[39;00m activations\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications \u001b[38;5;28;01mas\u001b[39;00m applications\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callbacks \u001b[38;5;28;01mas\u001b[39;00m callbacks\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chara\\OneDrive\\Pictures\\Documents\\MACHINE LEARNING\\HandWritingRecognizer\\mnist_env\\Lib\\site-packages\\keras\\activations\\__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deserialize \u001b[38;5;28;01mas\u001b[39;00m deserialize\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get \u001b[38;5;28;01mas\u001b[39;00m get\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m serialize \u001b[38;5;28;01mas\u001b[39;00m serialize\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chara\\OneDrive\\Pictures\\Documents\\MACHINE LEARNING\\HandWritingRecognizer\\mnist_env\\Lib\\site-packages\\keras\\src\\__init__.py:13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m regularizers\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m visualization\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasTensor\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Input\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chara\\OneDrive\\Pictures\\Documents\\MACHINE LEARNING\\HandWritingRecognizer\\mnist_env\\Lib\\site-packages\\keras\\src\\visualization\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_bounding_boxes\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_image_gallery\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chara\\OneDrive\\Pictures\\Documents\\MACHINE LEARNING\\HandWritingRecognizer\\mnist_env\\Lib\\site-packages\\keras\\src\\visualization\\plot_image_gallery.py:13\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_preprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase_image_preprocessing_layer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m      9\u001b[39m     BaseImagePreprocessingLayer,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     15\u001b[39m     plt = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chara\\OneDrive\\Pictures\\Documents\\MACHINE LEARNING\\HandWritingRecognizer\\mnist_env\\Lib\\site-packages\\matplotlib\\pyplot.py:57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcycler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cycler  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolorbar\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chara\\OneDrive\\Pictures\\Documents\\MACHINE LEARNING\\HandWritingRecognizer\\mnist_env\\Lib\\site-packages\\matplotlib\\colorbar.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpatches\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpatches\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpath\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmspines\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmtransforms\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _docstring\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1138\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1078\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1507\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1479\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1615\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(self, fullname, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:147\u001b[39m, in \u001b[36m_path_stat\u001b[39m\u001b[34m(path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1750265982952,
     "user": {
      "displayName": "Charan Gaming11",
      "userId": "16907770713425715637"
     },
     "user_tz": -330
    },
    "id": "rRm01No-sGf6",
    "outputId": "8f9cfd8d-8366-47ca-f776-cc53cc8ffb93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample labels: [5 0 4 1 9]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample labels:\", y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1750265983697,
     "user": {
      "displayName": "Charan Gaming11",
      "userId": "16907770713425715637"
     },
     "user_tz": -330
    },
    "id": "Qeos2NbVsBN3",
    "outputId": "8ed72174-4305-4499-f377-5ab635d881ba"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(10, 2))\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(x_train[i],cmap=\"gray\") # Gray for black and white\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1750265983711,
     "user": {
      "displayName": "Charan Gaming11",
      "userId": "16907770713425715637"
     },
     "user_tz": -330
    },
    "id": "DK5ajF_9uDn4",
    "outputId": "e799c543-bf60-4475-9acb-8001a02487e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1750265983734,
     "user": {
      "displayName": "Charan Gaming11",
      "userId": "16907770713425715637"
     },
     "user_tz": -330
    },
    "id": "AFNF3hvLt7w-"
   },
   "outputs": [],
   "source": [
    "# Reshape the input data to add a channel dimension\n",
    "# Original shape: (number of images, 28, 28)\n",
    "# New shape: (number of images, 28, 28, 1)\n",
    "# The '1' at the end represents the number of color channels (1 for grayscale)\n",
    "# This format is required by Conv2D layers in CNNs, which expect input in the form (height, width, channels)\n",
    "# Channel is like no of layers\n",
    "# NOTE: This does NOT change the pixel values — it only changes how the data is organized\n",
    "# For example:\n",
    "# [[100, 150],\n",
    "#  [200, 250]] → shape (2, 2)\n",
    "# becomes\n",
    "# [[[100], [150]],\n",
    "#  [[200], [250]]] → shape (2, 2, 1)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1750265984058,
     "user": {
      "displayName": "Charan Gaming11",
      "userId": "16907770713425715637"
     },
     "user_tz": -330
    },
    "id": "-FpJQkGBsf2E"
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values from [0, 255] to [0.0, 1.0] for faster and more stable training\n",
    "# 255 -> White 0 -> Black in the image\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1750265984129,
     "user": {
      "displayName": "Charan Gaming11",
      "userId": "16907770713425715637"
     },
     "user_tz": -330
    },
    "id": "tRt0Sv9xt5jX",
    "outputId": "d439bf1b-d9c2-44fa-c50c-2e016562addf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.01176471]\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.49411765]\n",
      "  [0.53333336]\n",
      "  [0.6862745 ]\n",
      "  [0.10196079]\n",
      "  [0.6509804 ]\n",
      "  [1.        ]\n",
      "  [0.96862745]\n",
      "  [0.49803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.11764706]\n",
      "  [0.14117648]\n",
      "  [0.36862746]\n",
      "  [0.6039216 ]\n",
      "  [0.6666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.88235295]\n",
      "  [0.6745098 ]\n",
      "  [0.99215686]\n",
      "  [0.9490196 ]\n",
      "  [0.7647059 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.19215687]\n",
      "  [0.93333334]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.9843137 ]\n",
      "  [0.3647059 ]\n",
      "  [0.32156864]\n",
      "  [0.32156864]\n",
      "  [0.21960784]\n",
      "  [0.15294118]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7764706 ]\n",
      "  [0.7137255 ]\n",
      "  [0.96862745]\n",
      "  [0.94509804]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.3137255 ]\n",
      "  [0.6117647 ]\n",
      "  [0.41960785]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8039216 ]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.16862746]\n",
      "  [0.6039216 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.05490196]\n",
      "  [0.00392157]\n",
      "  [0.6039216 ]\n",
      "  [0.99215686]\n",
      "  [0.3529412 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.54509807]\n",
      "  [0.99215686]\n",
      "  [0.74509805]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.04313726]\n",
      "  [0.74509805]\n",
      "  [0.99215686]\n",
      "  [0.27450982]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.13725491]\n",
      "  [0.94509804]\n",
      "  [0.88235295]\n",
      "  [0.627451  ]\n",
      "  [0.42352942]\n",
      "  [0.00392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.31764707]\n",
      "  [0.9411765 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.46666667]\n",
      "  [0.09803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.1764706 ]\n",
      "  [0.7294118 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.5882353 ]\n",
      "  [0.10588235]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.0627451 ]\n",
      "  [0.3647059 ]\n",
      "  [0.9882353 ]\n",
      "  [0.99215686]\n",
      "  [0.73333335]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.9764706 ]\n",
      "  [0.99215686]\n",
      "  [0.9764706 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.18039216]\n",
      "  [0.50980395]\n",
      "  [0.7176471 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8117647 ]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.15294118]\n",
      "  [0.5803922 ]\n",
      "  [0.8980392 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.98039216]\n",
      "  [0.7137255 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09411765]\n",
      "  [0.44705883]\n",
      "  [0.8666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7882353 ]\n",
      "  [0.30588236]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09019608]\n",
      "  [0.25882354]\n",
      "  [0.8352941 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7764706 ]\n",
      "  [0.31764707]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.67058825]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7647059 ]\n",
      "  [0.3137255 ]\n",
      "  [0.03529412]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.21568628]\n",
      "  [0.6745098 ]\n",
      "  [0.8862745 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.95686275]\n",
      "  [0.52156866]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.53333336]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.83137256]\n",
      "  [0.5294118 ]\n",
      "  [0.5176471 ]\n",
      "  [0.0627451 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1750265984131,
     "user": {
      "displayName": "Charan Gaming11",
      "userId": "16907770713425715637"
     },
     "user_tz": -330
    },
    "id": "LgzLhOwcwLhN"
   },
   "outputs": [],
   "source": [
    "# 🎯 One-Hot Encoding: Convert integer class labels (e.g., 0–9) into binary vectors\n",
    "# ------------------------------------------------------------\n",
    "# Neural networks can't directly understand class labels like [3, 7, 2]\n",
    "# because they may mistakenly treat them as numbers with order (e.g., 7 > 3).\n",
    "#\n",
    "# One-hot encoding solves this by converting each class label into a vector\n",
    "# with all 0s except a 1 at the index corresponding to the class.\n",
    "\n",
    "# For example:\n",
    "# Label:        3           →    One-hot: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "# Label:        7           →    One-hot: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "# This ensures that all classes are treated as distinct categories, not ordered numbers.\n",
    "\n",
    "# 🧠 Real-life Analogy:\n",
    "# Think of it like a checkbox question on a form asking for your favorite fruit:\n",
    "# [Apple] [Banana] [Mango✓] [Grapes] ... [Pineapple]\n",
    "# Only one is selected (1), the rest are unselected (0)\n",
    "\n",
    "# ✅ We use keras.utils.to_categorical to perform this transformation.\n",
    "# This is required for models with softmax output and categorical_crossentropy loss.\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1750265984337,
     "user": {
      "displayName": "Charan Gaming11",
      "userId": "16907770713425715637"
     },
     "user_tz": -330
    },
    "id": "FAWVcFKHxg3Z",
    "outputId": "49f55fd2-12f9-438b-dece-c19afcef37a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# You are given 28x28 grayscale images of digits.\n",
    "# Each image is just a grid of pixel values from 0 (black) to 255 (white).\n",
    "# You want your model to learn how a “2” looks different from a “7” — just like your brain does!\n",
    "\n",
    "# 👉 Let’s build the model one layer at a time\n",
    "\n",
    "model = Sequential()  # “Hey Keras, I want to build a model where each layer comes one after another.”\n",
    "\n",
    "# 🔍 Layer 1: First Convolution\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "# “Start with scanning the image using 32 filters of size 5×5.\n",
    "# Each filter is like a tiny window that slides across the image and detects basic patterns like edges or corners.\n",
    "# activation='relu' means: If a filter sees something important, keep it (positive values); else ignore it (zero).\n",
    "# input_shape=(28, 28, 1) means: Each image is 28×28 pixels with 1 color channel (black & white).”\n",
    "\n",
    "# 🔻 Layer 2: Max Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# “Okay, now that you found some features... reduce the image size.\n",
    "# From each 2×2 square, just keep the biggest value — this is called max pooling.\n",
    "# It makes the image smaller and keeps only the important stuff.”\n",
    "\n",
    "# 🔍 Layer 3: Second Convolution\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# “Let’s scan the reduced image again with 64 filters of size 3×3.\n",
    "# Now the model will learn more complex patterns like curves, parts of digits, etc.”\n",
    "\n",
    "# 🔻 Layer 4: More Pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# “Again, shrink the image by keeping only the strongest signals in each 2×2 patch.”\n",
    "\n",
    "# 🔄 Layer 5: Flattening\n",
    "model.add(Flatten())\n",
    "# “I’m done with all the scanning. Now flatten the 2D data (like a 3D cube) into a 1D list of numbers.\n",
    "# Why? Because now I want to make decisions, and decision-making layers expect a flat list.”\n",
    "\n",
    "# 🧠 Layer 6: Fully Connected Dense Layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# “Now use a layer with 128 brain-like neurons.\n",
    "# Each one will combine features from earlier to form ideas like:\n",
    "# 👉 ‘Maybe this is a loop of a 6’\n",
    "# 👉 ‘This corner and that edge look like a 7’”\n",
    "\n",
    "# 🔥 Layer 7: Dropout (Prevent Overfitting)\n",
    "model.add(Dropout(0.3))\n",
    "# “Let’s avoid overthinking!\n",
    "# Randomly turn off 30% of these neurons during training so the model doesn’t get too confident about one pattern.”\n",
    "\n",
    "# 🧠 Layer 8: Another Dense Layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# “Add another layer with 64 neurons.\n",
    "# Let them build more abstract features by combining ideas from the last layer.”\n",
    "\n",
    "# 🔥 Layer 9: Stronger Dropout\n",
    "model.add(Dropout(0.5))\n",
    "# “Again, turn off half the neurons while training — this prevents overfitting (memorizing instead of learning).”\n",
    "\n",
    "# 🎯 Output Layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "# “Finally, add 10 neurons — one for each digit (0 to 9).\n",
    "# Use softmax, which turns their outputs into probabilities.\n",
    "# If softmax says:\n",
    "# [0.01, 0.00, 0.96, 0.00, 0.00, 0.01, 0.00, 0.01, 0.00, 0.00]\n",
    "# Then it’s 96% confident this is the digit 2.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1750265984417,
     "user": {
      "displayName": "Charan Gaming11",
      "userId": "16907770713425715637"
     },
     "user_tz": -330
    },
    "id": "CwLqPZhSyTKt"
   },
   "outputs": [],
   "source": [
    "# ✅ Step: Compile the Model — tell Keras how to train\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,  # 🔺 “How wrong was the model?”\n",
    "    # Since our labels are one-hot encoded, we use categorical crossentropy.\n",
    "    # It compares the predicted probabilities with the actual one-hot vector like:\n",
    "    # Predicted: [0.1, 0.2, 0.7] vs Actual: [0, 0, 1]\n",
    "    # Lower the loss, the better the model is learning.\n",
    "\n",
    "    optimizer=keras.optimizers.Adadelta(),  # 🧠 “How should the model learn?”\n",
    "    # Adadelta is an optimizer — it adjusts weights automatically based on how wrong the model was.\n",
    "    # It’s adaptive, which means it updates faster when the model is confused and slows down when it's getting confident.\n",
    "\n",
    "    metrics=['accuracy']  # 📈 “What should we monitor while training?”\n",
    "    # We’ll keep track of accuracy — how many predictions were actually correct.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 755541,
     "status": "ok",
     "timestamp": 1750266739908,
     "user": {
      "displayName": "Charan Gaming11",
      "userId": "16907770713425715637"
     },
     "user_tz": -330
    },
    "id": "3zPrdHxO0zgm",
    "outputId": "446dae97-5966-49f6-aaf9-bd01baacce46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 108ms/step - accuracy: 0.1170 - loss: 2.3004 - val_accuracy: 0.2352 - val_loss: 2.2880\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 102ms/step - accuracy: 0.1428 - loss: 2.2898 - val_accuracy: 0.3172 - val_loss: 2.2757\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 105ms/step - accuracy: 0.1685 - loss: 2.2787 - val_accuracy: 0.3800 - val_loss: 2.2627\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 110ms/step - accuracy: 0.1963 - loss: 2.2668 - val_accuracy: 0.4154 - val_loss: 2.2489\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 106ms/step - accuracy: 0.2135 - loss: 2.2561 - val_accuracy: 0.4343 - val_loss: 2.2342\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 105ms/step - accuracy: 0.2291 - loss: 2.2440 - val_accuracy: 0.4498 - val_loss: 2.2186\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 101ms/step - accuracy: 0.2476 - loss: 2.2297 - val_accuracy: 0.4627 - val_loss: 2.2015\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 105ms/step - accuracy: 0.2659 - loss: 2.2139 - val_accuracy: 0.4746 - val_loss: 2.1824\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 113ms/step - accuracy: 0.2767 - loss: 2.1989 - val_accuracy: 0.4800 - val_loss: 2.1613\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 105ms/step - accuracy: 0.2919 - loss: 2.1793 - val_accuracy: 0.4893 - val_loss: 2.1373\n",
      "The model has successfully trained\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "hist = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "# ✅ This is where your model starts *learning* from the training data!\n",
    "# `fit` means: “Start training on x_train images to learn how to predict y_train labels”\n",
    "# It returns a `History` object (saved in `hist`) which records loss & accuracy over time\n",
    "\n",
    "# batch_size=batch_size\n",
    "# 🔁 “How many samples to show the model at once?”\n",
    "# If batch_size = 128, the model sees 128 images → adjusts weights → repeats\n",
    "# Smaller = slower but more accurate. Bigger = faster but may miss details.\n",
    "# 60000/128 = 469 per epoch\n",
    "\n",
    "# epochs=epochs\n",
    "# 🔄 “How many times to show the *entire training set*?”\n",
    "# If epochs = 10, it means the model sees all 60,000 images 10 times\n",
    "# More epochs = more learning, but also more time (and risk of overfitting)\n",
    "\n",
    "# verbose=1\n",
    "# 📢 “How much output do you want while training?”\n",
    "# 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "# 1 is perfect for most use cases — shows a live progress bar\n",
    "\n",
    "# validation_data=(x_test, y_test)\n",
    "# 🧪 After each epoch, test how well the model performs on *unseen* test data\n",
    "# This helps you monitor overfitting (training accuracy high, test accuracy low = overfitting)\n",
    "\n",
    "print(\"The model has successfully trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2801,
     "status": "ok",
     "timestamp": 1750267152071,
     "user": {
      "displayName": "Charan Gaming11",
      "userId": "16907770713425715637"
     },
     "user_tz": -330
    },
    "id": "2b796QP01Jkm",
    "outputId": "4cc39f1e-c337-4c3d-c626-bbeb8d8ff59b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.1373229026794434\n",
      "Test accuracy: 0.489300012588501\n",
      "Saving the model as mnist.h5\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save('mnist.h5')\n",
    "print(\"Saving the model as mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1750266742573,
     "user": {
      "displayName": "Charan Gaming11",
      "userId": "16907770713425715637"
     },
     "user_tz": -330
    },
    "id": "nJ98io7t6mPG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOxQxQ6J0FXGDsHgp+hS909",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mnist_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
